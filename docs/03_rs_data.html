<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 - Remote Sensing Learning Diary - 3&nbsp; Remote Sensing Data Manipulation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04_policy.html" rel="next">
<link href="./02_portfolio.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03_rs_data.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Remote Sensing Data Manipulation</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 - Remote Sensing Learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Started with Remote Sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_portfolio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Portfolio</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_rs_data.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Remote Sensing Data Manipulation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_policy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Policy Implications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_gge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Google Earth Engine</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="header-section-number">3.1</span> Summary</a>
  <ul class="collapse">
  <li><a href="#data-correction" id="toc-data-correction" class="nav-link" data-scroll-target="#data-correction"><span class="header-section-number">3.1.1</span> Data Correction</a></li>
  <li><a href="#data-joining-and-enhancement" id="toc-data-joining-and-enhancement" class="nav-link" data-scroll-target="#data-joining-and-enhancement"><span class="header-section-number">3.1.2</span> Data Joining and Enhancement</a></li>
  <li><a href="#glossary" id="toc-glossary" class="nav-link" data-scroll-target="#glossary"><span class="header-section-number">3.1.3</span> Glossary</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications"><span class="header-section-number">3.2</span> Applications</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="header-section-number">3.3</span> Reflection</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Remote Sensing Data Manipulation</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">3.1</span> Summary</h2>
<p>In order to use the remote sensing data most effectively, data manipulation is desired. This comes in two perspectives: correcting data to remove the impacts from unnecessary factors, and joining and enhansing data.</p>
<section id="data-correction" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="data-correction"><span class="header-section-number">3.1.1</span> Data Correction</h3>
<p>The <em>raw</em> data fetched from satellites are subject to interference by environmental factors. Data correction is required to correctly analyse the satellite imagery obtained. The following explains the various aspects of data correction.</p>
<p>Thankfully, the contemporary satellite imagery prouducts come in <strong>ARD: Analysis Ready Data</strong> so I am expecting we don’t need to worry too much about these jargons.</p>
<section id="atmospheric-correction" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="atmospheric-correction">Atmospheric Correction</h4>
<p>Removing the effect of atmosphere which absorbs and scatters light, leading to haze (reduced contrast of image) and the adjacency effect (nearby pixels bleeding into each other).</p>
<section id="relative-correction" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="relative-correction">Relative Correction</h5>
<p>Relative correction normalises intensities of bands within a single iamge or within multiple dates. The <strong>dark object subtraction (DOS)</strong> method assumes the darkest value in the image displays the effect of atmosphere, and subtracts that value from the whole image, leaving the actual surface reflectance value. Other methods such as <strong>pseudo-invariant features</strong> are proposed as well.</p>
<p>While these simple methods can calibrate values within one imagery, the <em>relative</em> nature does not allow for comparison between different imagery - this is where absolute correction comes into play.</p>
</section>
<section id="absolute-correction" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="absolute-correction">Absolute Correction</h5>
<p>Calculates the scaled absolute value for surface reflectance, enabling comparison between different places on earth. Multiple models are proposed, or a field work can be conducted to make the satellite observe the empirical line of spectrometer you laid out in the wild.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ars.els-cdn.com/content/image/3-s2.0-B9780128158265000040-f04-09-9780128158265.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Example of atmospheric correction. Image from <span class="citation" data-cites="liang2020">Liang and Wang (<a href="99_references.html#ref-liang2020" role="doc-biblioref">2020</a>)</span></figcaption>
</figure>
</div>
</section>
</section>
<section id="geometric-correction" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="geometric-correction">Geometric Correction</h4>
<p>Geometric correction is manipulation to fit the earth observation data into a reference system. This is similar to the process of georeferencing analog maps <span class="citation" data-cites="skopyk2021">(<a href="99_references.html#ref-skopyk2021" role="doc-biblioref">Skopyk 2021</a>)</span>.</p>
<p>This is achieved by taking several reference points (Ground Control Points) on the imagery where the actual coordinates are known, and interpolating the areas in between <span class="citation" data-cites="jensen2016">(<a href="99_references.html#ref-jensen2016" role="doc-biblioref">Jensen 2016</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://seos-project.eu/remotesensing/images/georeferenzieren.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Reference points on satellite imagery and the gold standard map (image from SEOS)</figcaption>
</figure>
</div>
<p>The actual mapping is done <em>backwards</em>, where points on the imagery are calculated from coordinates on the gold standard map, so that every point on the study area has its corresponding point on the imagery. This is modelled as follows.</p>
<p><span class="math display">\[
\begin{cases}
x^i = a_0 + a_1x + a_2y+\epsilon_i \\
y^i = b_0 + b_1x + b_2y+\epsilon_i \\
\end{cases}
\]</span></p>
<ul>
<li><span class="math inline">\((x^i, y^i)\)</span>: coordinates on the satellite imagery</li>
<li><span class="math inline">\((x, y)\)</span>: coordinates on the gold standard map</li>
</ul>
<p><strong>Orthorectification</strong> or topographic correction is one aspect of this, correcting the image so that it is viewed at <em>nadir</em>. One method is cosine correction, where the radiance is calculated as:</p>
<p><span class="math display">\[
L_H = L_T \frac{\cos \theta_O}{\cos i}
\]</span></p>
<ul>
<li><span class="math inline">\(L_T\)</span>: radiance (TOA) from sloped terrain</li>
<li><span class="math inline">\(\theta_O\)</span>: zenith angle of the sun</li>
<li><span class="math inline">\(i\)</span>: sun’s incidence angle (angle between rays and normal of surface)</li>
</ul>
<p>This will be important especially if using imagery from aircrafts flying at relatively low altitude compared to satellites.</p>
</section>
<section id="radiometric-calibration" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="radiometric-calibration">Radiometric Calibration</h4>
<p>The original satellite imagery stores data using <strong>digital numbers (DN)</strong> which has no units! This needs to be translated into values with meaningful units.</p>
</section>
</section>
<section id="data-joining-and-enhancement" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="data-joining-and-enhancement"><span class="header-section-number">3.1.2</span> Data Joining and Enhancement</h3>
<p>We do not need to use the data as is, but are open to wrangling data for analysis as well.</p>
<section id="joining" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="joining">Joining</h4>
<p>Joining is the procedure of combining separate images from different data sources to cover the whole study area. Also called mosaicking. The algorithm behind this is called a histogram matching algorithm, where the 2 images are given similar brightness values.</p>
</section>
<section id="enhancements" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="enhancements">Enhancements</h4>
<p>Images may be enhanced to improve the appearance or results of analysis.</p>
<p>There are many enhancement methods. One simple method is <strong>contrast enhancement</strong> where image band not making use of the whole spectrum range are expanded so that the contrast is maximised.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.earthdatascience.org/images/earth-analytics/raster-data/raster-image-stretch-light.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Example of image stretch by contrast enhancement. Image from <span class="citation" data-cites="earthlab2018">EarthLab (<a href="99_references.html#ref-earthlab2018" role="doc-biblioref">2018</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="ratio-enhancements" class="level4" data-number="3.1.2.1">
<h4 data-number="3.1.2.1" class="anchored" data-anchor-id="ratio-enhancements"><span class="header-section-number">3.1.2.1</span> Ratio enhancements</h4>
<p>The one I found interesting was ratio enhancements, where the manipulation between different bands enabling us to gain insights from the results.</p>
<p>One example of this is the normalised difference vegetation index (NDVI), where a high value indicates healthy vegetation. The calculation is as follows, and I was surprised how simple this value could be calculated!</p>
<p><span class="math display">\[
\text{NDVI} = \frac{\text{NIR}-\text{red}}{\text{NIR}+\text{red}}
\]</span></p>
<p>I have applied this to a dataset from Landsat 8 for southeast England, where I merged 2 datasets to cover a wider area.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week3/NDVI_london.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">NDVI of Southeast England</figcaption>
</figure>
</div>
<p>It is interesting to see that you can make out the patch with low value on the right hand side which is Central London, and that you can see the vegetation has a range in its healthiness; if you look at the optical imagery it is hard to tell the differences between healthy and unhealthy vegetation.</p>
<p>Let’s zoom in to the London Borough of Camden - home to two major patches of urban green space: Hampstead Heath and Regent’s Park.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week3/NDVI_camden.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">NDVI of the London Borough of Camden</figcaption>
</figure>
</div>
<p>You can easily make out Regent’s Park and Primrose Hill at the bottom left and Hampstead Heath at the top, which are home to the healthiest patches of vegetation in this area. Smaller patches have smaller NDVI value, indicating they are unhealthier compared to that of parks. If you compare the scale to the bigger picture above, you can see that the maximum value is lower in Camden. Understandable, but it is great you can see the difference!</p>
</section>
<section id="other-techniques" class="level4" data-number="3.1.2.2">
<h4 data-number="3.1.2.2" class="anchored" data-anchor-id="other-techniques"><span class="header-section-number">3.1.2.2</span> Other techniques</h4>
<p>Other enhancement techniques covered include the following:</p>
<ul>
<li><em>Filtering</em> sharpens (high-pass) or averages (low-pass) surrounding cells in order to capture particular characteristics</li>
<li><em>PCA</em> is a method of dimension reduction, taking multiple bands and combining them into a smaller number of bands.</li>
<li><em>Texture</em> considers the difference of values between moving windows, allowing for edges of certain object to be clearer.</li>
</ul>
<p>I calculated the texture value using the red band for the London Borough of Camden, and the results are shown below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week3/textures_camden.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Texture of Camden</figcaption>
</figure>
</div>
<p>I must admit it is difficult to make out individual differences, but you can see the areas around King’s Cross, St.&nbsp;Pancras and Euston stations having a smaller texture value. It seems to be successfully identifying the different characteristics of urban landscape!</p>
</section>
</section>
<section id="glossary" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="glossary"><span class="header-section-number">3.1.3</span> Glossary</h3>
<p>There were a lot of new terminology introduced in this session.</p>
<section id="data-correction-vocabulary" class="level4" data-number="3.1.3.1">
<h4 data-number="3.1.3.1" class="anchored" data-anchor-id="data-correction-vocabulary"><span class="header-section-number">3.1.3.1</span> Data Correction Vocabulary</h4>
<ul>
<li><strong>nadir</strong>: looking straight down, not at an angle.</li>
<li><strong>zenith</strong>: point vertically above observer. <strong>Zenith Angle</strong> is the angle between object and zenith.</li>
<li><strong>incident angle</strong>: the angle between the normal of the sloped terrain and the sun. If horizontal, this matches the zenith angle.</li>
<li><strong>azimuth</strong>: the compass angle of the sun, measured from the north. Same idea with <a href="https://en.wikipedia.org/wiki/Runway#Naming">runway names</a>!</li>
</ul>
</section>
<section id="data-enhancement-vocabulary" class="level4" data-number="3.1.3.2">
<h4 data-number="3.1.3.2" class="anchored" data-anchor-id="data-enhancement-vocabulary"><span class="header-section-number">3.1.3.2</span> Data Enhancement Vocabulary</h4>
<ul>
<li><strong>Image Stretch</strong>: expanding the range of bands so that it utilises the whole range of values allowed</li>
<li><strong>Texture</strong>: calculating the value across a certain window and comparing with adjacent values, allowing to identify edges of features</li>
<li><strong>PCA</strong>: a method of dimension reduction</li>
</ul>
</section>
</section>
</section>
<section id="applications" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="applications"><span class="header-section-number">3.2</span> Applications</h2>
<p>I will look at 2 papers that measure the accuracy of image segmentation using different color bands and methodologies.</p>
<p><span class="citation" data-cites="trias-sanz2008">Trias-Sanz, Stamon, and Louchet (<a href="99_references.html#ref-trias-sanz2008" role="doc-biblioref">2008</a>)</span> explores the usage of colour bands and textures to identify objects within an image. Using multiple bands, the paper attempts to optimise the best parameter that successfully identifies different objects in an imagery of a rural area. The paper addresses the varying scale of focus in the project, whether to focus on individual trees within a field or the field as a total. It also discusses the multiple ways of data enhancement, and tries to optimise which parameters and transformed channels should be used to achieve the best results for object segmentation.</p>
<p><span class="citation" data-cites="kupidura2019">Kupidura (<a href="99_references.html#ref-kupidura2019" role="doc-biblioref">2019</a>)</span> analysed multiple methods of texture analysis to compare the accuracy of identifying different land cover types. 3 types of texture extraction was considered, the GLCM (Gray Level Co-occurance Matrix), Laplace Filters and Granulometric Analysis. The first two methods seem to be more popular among remote sensing analysis, and a third method which is less known. The results indicate the granulometric analysis is the best methodology in terms of identifying different usages from satellite imagery, although I get the feeling that the authors are trying to promote this methodology that they have been using for previous research, since the merit of the granulometric analysis derives from mitigation of the edge effect, a problem which the two other methods have in common. Maybe comparing different methodologies to overcome the edge effect would have been more persuasive (or, maybe this in itself is quite an achievement. I might need more knowledge in this field to answer that question.)</p>
<p>Both of the papers address the accuracy of image segmentation using many possible index channels, where we try to identify the objects that appear in the satellite imagery. The first paper has a focus on tweaking parameters within a single methodology, while the second paper focuses on choosing the correct method given a remote sensing dataset. The 10-year difference between these papers might have seen a dramatic advance in technology, but I have the impression that trying to make image segmentation as accurate as possible is an essential part of EO data analysis.</p>
</section>
<section id="reflection" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">3.3</span> Reflection</h2>
<p>Data correction is the first thing we have covered this week, and I cannot believe analysis ready data is provided after all this manipulation. Although I might not do the data correction myself, I should be prepared to understand the differences between the multiple products of satellite imagery, and be able to choose which one I should be using for analysis.</p>
<p>I feel very thankful for the people trying to improve the algorithm behind analyses; which I could not get my head around. The idea of taking multiple bands and adjacent pixels are interesting enough already, and trying to make out different features are wonderful!</p>
<p>After a few weeks, I am starting to understand the variety of things you can do using satellite imagery. I did not have the idea of taking adjacent values and calculate indeces that act as indicators of change among the different datasets, which helps differentiate between objects within the imagery. I am feeling I should deep-dive into the different indeces developed by other researchers, to see what can be highlighted using simple combinations of different bands!</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-earthlab2018" class="csl-entry" role="listitem">
EarthLab. 2018. <span>“Learn to <span>Use NAIP Multiband Remote Sensing Images</span> in <span>Python</span>.”</span> <em>Earth Data Science - Earth Lab</em>. https://www.earthdatascience.org/courses/use-data-open-source-python/multispectral-remote-sensing/intro-naip/.
</div>
<div id="ref-jensen2016" class="csl-entry" role="listitem">
Jensen, John R. 2016. <em>Introductory Digital Image Processing: A Remote Sensing Perspective / <span>John R</span>. <span>Jensen</span> (<span>University</span> of <span>South Carolina</span>).</em> 4th edition. Pearson Series in Geographic Information Science. <span>Glenview, IL</span>: <span>Pearson Education, Inc.</span>
</div>
<div id="ref-kupidura2019" class="csl-entry" role="listitem">
Kupidura, Przemysław. 2019. <span>“The <span>Comparison</span> of <span>Different Methods</span> of <span>Texture Analysis</span> for <span>Their Efficacy</span> for <span>Land Use Classification</span> in <span>Satellite Imagery</span>.”</span> <em>Remote Sensing</em> 11 (10): 1233. <a href="https://doi.org/10.3390/rs11101233">https://doi.org/10.3390/rs11101233</a>.
</div>
<div id="ref-liang2020" class="csl-entry" role="listitem">
Liang, Shunlin, and Jindi Wang, eds. 2020. <span>“Chapter 4 - <span>Atmospheric</span> Correction of Optical Imagery.”</span> In <em>Advanced <span>Remote Sensing</span> (<span>Second Edition</span>)</em>, 131–56. <span>Academic Press</span>. <a href="https://doi.org/10.1016/B978-0-12-815826-5.00004-0">https://doi.org/10.1016/B978-0-12-815826-5.00004-0</a>.
</div>
<div id="ref-skopyk2021" class="csl-entry" role="listitem">
Skopyk, Brad. 2021. <span>“Georeferencing <span>Historical Maps</span>.”</span> <em>ArcGIS StoryMaps</em>. https://storymaps.arcgis.com/stories/dd75d0398f7d4ded924d303161895b8b.
</div>
<div id="ref-trias-sanz2008" class="csl-entry" role="listitem">
Trias-Sanz, Roger, Georges Stamon, and Jean Louchet. 2008. <span>“Using Colour, Texture, and Hierarchial Segmentation for High-Resolution Remote Sensing.”</span> <em>ISPRS Journal of Photogrammetry and Remote Sensing</em> 63 (2): 156–68. <a href="https://doi.org/10.1016/j.isprsjprs.2007.08.005">https://doi.org/10.1016/j.isprsjprs.2007.08.005</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02_portfolio.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Portfolio</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04_policy.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Policy Implications</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>